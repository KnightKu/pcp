#!/usr/bin/python
""" This program copies a directory tree in parallel.

Algorithm:

pcp implements a master-slave pattern. R0 is the master and R1...RX are the
slaves. R0 scan the source directory tree and put files to be copied on a
queue on the master. The master dispatches files in the queue to ranks R1..RX,
which do the copy."""
# Parallel cp program
# Copyright (c) Genome Research Ltd 2012
# Author Guy Coates <gmpc@sanger.ac.uk>
# This program is released under GNU Public License V2 (GPLv2)


import rpdb2
rpdb2.start_embedded_debugger("XXXX", fAllowRemote=True,timeout=10)

import argparse
import hashlib
import fnmatch
import os
import stat
import sys
import traceback
import time
import ctypes
import sqlite3
import pickle
import math
import signal
import gzip

from pcplib import fastwalk
from pcplib import lustreapi
from collections import deque
from mpi4py import MPI
import pkg_resources

try:
    __version__ = pkg_resources.require("pcp")[0].version
except pkg_resources.DistributionNotFound:
    __version__ = "UNRELEASED"

clib = ctypes.CDLL("libc.so.6", use_errno=True)

class Timer:
    """Simple timer / stopwatch class."""
    def __init__(self):
        self.running = False
        self.elapsedtime = 0
        self.stoptime = 0
        self.starttime = 0

    def reset(self):
        """Reset the timer to 0."""
        self.__init__()

    def start(self):
        """Start the timer."""
        self.running = True
        self.starttime = time.time()

    def stop(self):
        """Stop the timer."""
        self.running = False
        self.stoptime = time.time()
        self.elapsedtime += self.stoptime - self.starttime

    def read(self):
        """Get the elapsed time."""
        if self.running:
            return (time.time() - self.starttime) + self.elapsedtime
        else:
            return self.elapsedtime

def timestamp():
    return time.strftime("%b %d %H:%M:%S")


def createDB():
# This database holds all the information about files to be copied,
# their checksums as well as the state of the copy.
# State 
# 0 Not copied.
# 1 Dispatched for copy.
# 2 Copy complete.
# 3 Dispatched for md5
# 4 md5 complete

    filedb = sqlite3.connect(":memory:")
    filedb.text_factory = str
    filedb.execute("""CREATE TABLE FILECPY(
ID INTEGER PRIMARY KEY AUTOINCREMENT,
FILENAME TEXT,
STATE INTEGER DEFAULT 0,
SRCMD5 TEXT,
SIZE INTEGER,
CHUNKS INTEGER DEFAULT -1,
ATTEMPTS INTEGER DEFAULT 0,
LASTRANK INTEGER DEFAULT 0)""")
    filedb.execute("""CREATE INDEX COPY_IDX ON FILECPY(STATE, LASTRANK)""")
    filedb.execute("""CREATE INDEX MD5_IDX ON FILECPY(STATE, SIZE, LASTRANK)""")
    filedb.execute("""CREATE TABLE DIRLIST (
ID INTEGER PRIMARY KEY AUTOINCREMENT,
DIRNAME TEXT,
MTIME INTEGER,
ATIME INTEGER)""")

    # Table to hold program arguments
    filedb.execute("""CREATE TABLE ARGUMENTS(
ID INTEGER PRIMARY KEY AUTOINCREMENT,
ARGS BLOB)""")
    return(filedb)

# Dump the database out to disk
def dumpDB(statedb, filename):
    tmpfile = filename+"__PARTIAL__"
    dbfile = gzip.open(tmpfile, "wb")
    for l in statedb.iterdump():
        dbfile.write(l + "\n")
    dbfile.close()
    os.rename(tmpfile, filename)

# Restore the database state from a previous run so we
# can resume a copy.
def restoreDB(filename):
    filedb = sqlite3.connect(":memory:")
    filedb.text_factory = str
    dumpfile = gzip.open(filename, "rb")
    filedb.executescript(dumpfile.read())
    filedb.commit()
    dumpfile.close()
    argp = filedb.execute("SELECT ARGS FROM ARGUMENTS WHERE ID == 1").fetchone()
    args = pickle.loads(argp[0])

    filedb.execute("UPDATE FILECPY SET STATE = 0 WHERE STATE = 1;")
    filedb.execute("UPDATE FILECPY SET STATE = 2 WHERE STATE = 3;")
    filedb.execute("UPDATE FILECPY SET ATTEMPTS = 0;")
    filedb.execute("UPDATE FILECPY SET LASTRANK = 0;")
    return(filedb, args)
    

def parseargs():
    parser = MPIargparse(description=
                                     "Copy a directory tree in parallel",
                                     formatter_class =
                                     argparse.RawDescriptionHelpFormatter,
                                   epilog="""

This program traverses a directory tree and copies files in the tree in
parallel. It does not copy individual files in parallel. It should be invoked
via mpirun.

If run with the -l flag or -lf flags pcp will be stripe aware. -l will cause
stripe information to be copied from the source files and directories. -lf will 
cause all files and directories on the destination to be striped, regardless of
the striping on the source.

Striping behaviour can be further modified with -ls and -ld. A minimum file size
can be set with -ls. Files below this size will not be striped, regardless of
the souce striping. -ld will cause all directories to be unstriped.

-l requires that the source and destination filesystems must be lustre.
-lf can be used when only the destination filesystem is lustre.

For maximum efficiency, ensure tasks are spread across as many different
machines as possible to prevent local network bottlenecks.

""")


    parser.add_argument("SOURCE", help="source directory", nargs="?")
    parser.add_argument("DEST", help="destination directory", nargs="?")

    parser.add_argument("-c", help="verify copy with checksum", default=False,
                        action="store_true")
    parser.add_argument("-d", help="dead worker timeout (seconds)", default=10,
                        type=int)
    parser.add_argument("-g", help="only copy files matching glob",
                        default=None)
    parser.add_argument("-n", "--dry-run",
                        help="perform a trial run with no copies made",
                        action="store_true", default=False)
    parser.add_argument("-t",
                        help="retry file copies N times in case of IO errors",
                        type=int, metavar="N", default=3)
    parser.add_argument("-p", help="preserve ownership/permissions",
                        default=False, action="store_true")
    parser.add_argument("-v", help="verbose", default=False,
                        action="store_true")
    parser.add_argument("-V", "--version", help="print version number",
                        action='version',
                        version=os.path.basename(sys.argv[0]) + \
                            " version " + __version__)
    group = parser.add_mutually_exclusive_group()
    group.add_argument("-l", help="copy lustre stripe information",
                       default=False, action="store_true")
    group.add_argument("-lf",
                       help=("Force striping of all files and directories. Can be combined"
                             " with -ls and -ld."), default=False, action="store_true")
    parser.add_argument("-ls",
                        help=("do not stripe files smaller than B "
                              "bytes. Implies -l. Size can be suffixed"
                              "with k,M,G,T,P"), metavar="B", default=0)
    parser.add_argument("-ld",
                        help="Do not stripe diretories.", default=False,
                        action="store_true")

    parser.add_argument("-R",
                        help=("Restart a copy from a checkpoint file DUMPFILE."),
                        type=str, metavar="DUMPFILE", default=None)

    parser.add_argument("-K",
                       help=("Enable and write checkpoints to file DUMPFILE."),
                       type=str, metavar="DUMPFILE", default=None)
    parser.add_argument("-Km",
                        help=("Checkpoint every N minutes."),
                        type=int, metavar="N", default=60)

    if len(sys.argv) == 1:
        parser.print_help()
        Abort()
        
    args = parser.parse_args()

    if not args.SOURCE and  not args.R:
        print "You must specify a source directory!"
        parser.print_help()
        Abort()

    if not args.DEST and  not args.R:
        print "You must specify a destination directory!"
        parser.print_help()
        Abort()

    if args.ls != 0:
        args.ls = SIConvert(args.ls)
        if args.ls == -1:
            print "Error: incorrect size specification."
            Abort()
    return(args)

def Abort():
    if rank == 0 and STARTEDCOPY and DUMPDB:
        try:
            print "Attempting write state database to %s..." %(DUMPDB),
            dumpDB(statedb, DUMPDB)
            print "Done."
        except IOError as dberr:
            print "FAILED!" 
            print dberr

    """Clean down all the MPI Processes."""
    MPI.COMM_WORLD.Abort(1)
    exit (1)

def sanitycheck(sourcedir, destdir):
    """Perform some sanity checks, including creating the destination
    directory if it does not exist and ensuring excessive parallelism is not
    used."""

    realsource = os.path.realpath(sourcedir)
    realdest = os.path.realpath(destdir)
    if realsource == realdest:
        print 
        print ("ERROR: Source and destination directory are the same!")
        print
        Abort()
        
    # If we are using lustre stripe options, check that the source and/or
    # destination filesystems are lustre   
    if LSTRIPE:
        try:
            lustreapi.getstripe(sourcedir)
        except IOError, error:
            if error.errno == 25:
                print ("ERROR: You have asked me to copy lustre striping attributes, but"
                       " %s is not a lustre directory.") % sourcedir
                print "Exiting."
                Abort()


def scantree(sourcedir, statedb):
    """Scans sourcedir recursively and returns a list of filestate objects and
    a list of directories."""

    print "R%i: Scanning list of files to copy..." % (rank)
    if not  os.path.isdir(sourcedir):
        print "R%i: Error: %s not a directory" % (rank, sourcedir)
        Abort()
    startime = time.time()
    statedb.execute("""INSERT INTO DIRLIST (DIRNAME) VALUES(?)""",
                    (sourcedir,))
    for source, dirs, files in fastwalk.fastwalk(sourcedir):
        dirlist = [(os.path.join(source, d),) for d in dirs ]
        statedb.executemany("""INSERT INTO DIRLIST (DIRNAME) VALUES (?)""",
                            dirlist)
        fullpath = [ (os.path.join(source, f),) for f in files ]
        statedb.executemany("""INSERT INTO FILECPY (FILENAME) VALUES (?)""",
                            fullpath)

    endtime = time.time()
    walltime = endtime - startime
    totalfiles = statedb.execute("SELECT COUNT(*) FROM FILECPY").fetchone()[0]
    totaldirs = statedb.execute("SELECT COUNT(*) FROM DIRLIST").fetchone()[0]
    rate = (totalfiles + totaldirs) / walltime
    walltime = time.strftime("%H hrs %M mins %S secs",
                             time.gmtime(walltime))
    print ("R%i: Scan Done. Did %i files, %i dirs in %s"
           " (%.0f items/sec)."
        % (rank, totalfiles, totaldirs, walltime, rate))
    return()

def fadviseSeqNoCache(fileD):
    """Advise the kernel that we are only going to access file-descriptor
    fileD once, sequentially."""
    POSIX_FADV_SEQUENTIAL = 2
    POSIX_FADV_DONTNEED = 4
    offset = ctypes.c_int64(0)
    length = ctypes.c_int64(0)
    clib.posix_fadvise(fileD, offset, length, POSIX_FADV_SEQUENTIAL)
    clib.posix_fadvise(fileD, offset, length, POSIX_FADV_DONTNEED)

def md5copy(src, dst, blksize, MD5SUM, chunk):
    """Combined copy / md5 calcuation function. Copies data from src to dst in
    blksize chunks. If MD5SUM is true, it also calculates the md5sum of the
    source file. Returns the md5sum of the source and the number of bytes copied."""
    md5hash = hashlib.new("md5")
    bytescopied = 0
    infile = open(src, "rb")

    if chunk < 0:
        # Copy the file in one go:
        outfile = open(dst, "wb")
        fadviseSeqNoCache(infile.fileno())
        fadviseSeqNoCache(outfile.fileno())
        while True:
            data = infile.read(blksize)
            if not data:
                break
            outfile.write(data)
            bytescopied += len(data)
            if MD5SUM:
                md5hash.update(data)
    
    else:
        # copy CHUNKSIZE bytes:
        outfile = open(dst, "r+")
        fadviseSeqNoCache(infile.fileno())
        fadviseSeqNoCache(outfile.fileno())
        infile.seek(chunk*CHUNKSIZE)
        outfile.seek(chunk*CHUNKSIZE)
        
        nreads, remainder = divmod(CHUNKSIZE, blksize)
        for i in xrange(nreads):
            data = infile.read(blksize)
            outfile.write(data)
            bytescopied += len(data)
            if MD5SUM:
                md5hash.update(data)
        if remainder > 0:
            data = infile.read(remainder)
            outfile.write(data)
            bytescopied += len(data)
            if MD5SUM:
                md5hash.update(data)

    infile.close()
    outfile.close()
    digest = md5hash.hexdigest()

    if not MD5SUM:
        digest = None
    return(digest, bytescopied)

def createstripefile(src, dst, size):
    """Create a file dst with the lustre stripe information copied from src, unless 
    filesystem is < size, in which case we set the striping to 1."""
    stripestatus = 0
    if LSTRIPE:
        layout = lustreapi.getstripe(src)
    if (LSTRIPE and layout.isstriped()) or FORCESTRIPE:
        if size < MINSTRIPESIZE:
            stripestatus = -1
            count = 1
        else:
            stripestatus = 1
            count = -1
    else:
        count = 1
    if not DRYRUN:
        try:
            lustreapi.setstripe(dst, stripecount=count)
        except IOError, error:
            if error.errno == 17:
                # file exists; blow it away and try again...
                os.remove(dst)
                lustreapi.setstripe(dst, stripecount=count)
            else:
                raise

    return(stripestatus)

def calcmd5(filename, chunk):
    """calculate the md5sum of a file. Returns a tuple of  (md5sum,amount of
    data checksummed), or (None,0) in the case of symlinks."""
    md5hash = hashlib.new("md5")

    # Use the optimal blocksize for IO.
    filestat = safestat(filename)
    blksize = filestat.st_blksize
    mode = filestat.st_mode

    byteschecked = 0

    if stat.S_ISLNK(mode):
        return(None, byteschecked)

    fh = open(filename, "rb")
    fadviseSeqNoCache(fh.fileno())
    # MD5 the whole file
    if chunk < 0:
        while True:
            data = fh.read(blksize)
            byteschecked += len(data)
            if not data:
                break
            md5hash.update(data)

    else:
        #MD5 just our chunk
        fh.seek(chunk*CHUNKSIZE)
        nreads, remainder = divmod(CHUNKSIZE, blksize)
        for i in xrange(nreads):
            data = fh.read(blksize)
            md5hash.update(data)
            byteschecked += len(data)
        if remainder > 0:
            data = fh.read(remainder)
            md5hash.update(data)
            byteschecked += len(data)
            
    fh.close()
    digest = md5hash.hexdigest()
    return(digest, byteschecked)


def ConsumeWork(sourcedir, destdir):
    """Listen for work from the dispatcher and copies/md5sums files as
    appropriate. When send the SHUTDOWN message the worker will send
    performance stats back to the master."""

    filescopied = 0
    md5done = 0
    bytescopied = 0
    byteschksummed = 0
    md5timer = Timer()
    copytimer = Timer()

    # Poll for work.
    while True:
        msg = comm.recv(source=0, tag=1)
        action = msg[0]
        if action == "SHUTDOWN":
            break
        (filename, idx, chunk) = msg[1]
        md5sum = None
        destination = mungePath(sourcedir, destdir, filename)

        if action == "COPY":
            copytimer.start()
            try:
                size, speed, md5sum, stripestatus, status = \
                    copyFile(filename, destination, chunk)

            except (IOError, OSError) as error:
                speed = 0
                size = 0
                stripestatus = 0
                # permission denied errors are not fatal. Skip over the file
                # and carry on.
                if error.errno == 13:
                    status = 3
                # File might have moved whilst we copied it!
                elif error.errno == 2:
                    status = 5
                else:
                    status = 1

            if status == 0 or status == 4 :
                bytescopied += size
                filescopied += 1
            msg = ("COPYRESULT",( md5sum, idx, rank, status, speed,
                                  size, stripestatus))
            comm.send(msg, dest=0, tag=1)
            copytimer.stop()

        if action == "MD5":
            md5timer.start()
            if DRYRUN:
                size = 0
                status = 0
                md5sum = "DEADBEAFdeadbeafDEADBEAFdeadbeaf"
            else:
                try:
                    md5sum, size = calcmd5(destination, chunk)
                    status = 0
                except (IOError, OSError):
                    size = 0
                    status = 1
            msg = ("MD5RESULT", (md5sum, idx, rank, status, None, None, None))
            comm.send(msg, dest=0, tag=1)
            md5done += 1
            byteschksummed += size
            md5timer.stop()

    # Return stats
    comm.gather((filescopied, md5done, bytescopied, byteschksummed,
                 copytimer.read(), md5timer.read()), root=0)
    
    return(0)

def copyDirectories(sourcedir, destdir, statedb):
    """Copy a list of directories in the statedb from sourcedir to destdir"""
    global WARNINGS
    for idx, d in statedb.execute("SELECT ID, DIRNAME FROM DIRLIST"):
        destination = mungePath(sourcedir, destdir, d)
        if DRYRUN:
            if VERBOSE:
                print "R%i: %s mkdir %s" % (rank, timestamp(), destination)
        else:
            i = 0
            while i < MAXTRIES:
                try:
                    createDir(d, destination, statedb, idx)
                    break
                except IOError, error:
                    i += 1
                    print "R%i %s WARNING: mkdir error on %s attempt %i" \
                        % (rank, timestamp(), destdir, i)
                    WARNINGS += 1
                    if i == MAXTRIES:
                        print "R%i %s ERROR: Max number of retries on %s exceeded" \
                            % (rank, timestamp(), sourcedir)
                        raise


def checkAlive(rank, workers, timeout):
    """Quirky farm nodes can cause the MPI runtime to lock up during the task
    spawn. This routine checks whether nodes can exchange messages. If a node
    has not responded after timeout seconds we bail."""

    if rank > 0:
        msg = ("ALIVE", (rank,))
        comm.send(msg, dest=0, tag=3)
    else:
        expectedworkers = set(range(1, workers))
        aliveworkers = set()
        giveuptime = time.time() + timeout
        while time.time() < giveuptime:
            if comm.Iprobe(source=MPI.ANY_SOURCE, tag=3):
                msg = comm.recv(source=MPI.ANY_SOURCE, tag=3)
                status = msg[0]
                rank = msg[1][0]

                aliveworkers.add(rank)
                if len(aliveworkers) == len(expectedworkers):
                    print "R0: All workers have reported in."
                    return
        print ("Error: The following workers did not report in after"
               " %i seconds") % timeout
        awol = expectedworkers.difference(aliveworkers)
        for i in awol:
            print "R%i" % i
        Abort()

def DispatchWork(statedb):
    """The dispatcher sends  copy/md5 tasks out to idle workers. If copy/md5
    tasks fail the dispatcher will re-queue them for retries."""

    global WARNINGS
    global CHECKPOINTNOW
    global COPYREMAINS
    global MD5REMAINS

    # Queue containing worker who are ready for work.
    idleworkers = deque()
    idleworkers.extend(range(1, workers))
    # Start the checkpoint timer
    if DUMPDB:
        cptimer = Timer()
        cptimer.start()

    COPYREMAINS = statedb.execute \
        ("""SELECT COUNT(*) FROM FILECPY WHERE STATE == 0""").fetchone()[0]
        
    MD5REMAINS = statedb.execute \
        ("""SELECT COUNT(*) FROM FILECPY WHERE STATE < ?""",(ENDSTATE,)).fetchone()[0]

    if not MD5SUM:
        MD5REMAINS = 0

    # loop until we have no more work to send.
    while COPYREMAINS > 0 or MD5REMAINS > 0:
        # See if we need to checkpoint
        if DUMPDB:
            if cptimer.read() > DUMPINTERVAL:
                print "RO: Writing checkpoint to %s..." %DUMPDB,
                dumpDB(statedb, DUMPDB)
                print "Done"
                cptimer.reset()
                cptimer.start()

        if CHECKPOINTNOW:
            if not DUMPDB:
                dumpfile = "pcp_checkpoint.db"
            else:
                dumpfile = DUMPDB
            print "R0: SIGUSR1: Writing checkpoint to %s..." %dumpfile,
            dumpDB(statedb, dumpfile)
            print "Done"
            CHECKPOINTNOW = False

        # Listen for workers reporting in and deal with the results
        if comm.Iprobe(source=MPI.ANY_SOURCE, tag=1):
            msg = comm.recv(source=MPI.ANY_SOURCE, tag=1)
            action = msg[0]
            payload = msg[1]

            workerrank = msg[1][2]
            idleworkers.appendleft(workerrank)

            if action == "COPYRESULT":
                processCopy(statedb, payload)

            if action == "MD5RESULT":
                processMD5(statedb, payload)

        # try for dispatch
        if len(idleworkers) > 0:
            worker = idleworkers.pop()
            
            # 2 workers is a special case; we can't do MD5sum or retries on
            # a different nodes, as we only have 1 worker node.
            if workers == 2:
                lastrank = -1
            else:
                lastrank = worker

            task = statedb.execute("""SELECT * FROM FILECPY WHERE STATE == 0 AND
                                  LASTRANK <> ? LIMIT 1""",(lastrank, )).fetchone()
            if task:
                statedb.execute("""UPDATE FILECPY SET STATE = 1 WHERE ID = ?""",(task[0],))
                msg = ("COPY", (task[1], task[0], task[5]))
                comm.send(msg, dest=worker, tag=1)
                continue

            if MD5SUM:
                # We now know the size, and can improve load balancing between workers by
                # selecting the largest files first.
                task = statedb.execute("""SELECT * FROM FILECPY WHERE STATE == 2 AND
                       LASTRANK <> ? ORDER BY SIZE DESC LIMIT 1""",(lastrank, )).fetchone()
                if task:
                    statedb.execute("""UPDATE FILECPY SET STATE = 3 WHERE ID = ?""",(task[0],))
                    msg = ("MD5", (task[1], task[0], task[5]))
                    comm.send(msg, dest=worker, tag=1)
                    continue
            # There is work, but not for this worker. Send to the back of the queue
            idleworkers.appendleft(worker)

    if VERBOSE:
        print "R0: No more work to do."

def processMD5(statedb, payload):
    global WARNINGS
    global COPYREMAINS
    global MD5REMAINS

    md5sum = payload[0]
    idx = payload[1]
    workerrank = payload[2]
    status = payload[3]
    speed = payload[4]
    size = payload[5]
    stripestatus = payload[6]

    filename, attempt, srcmd5, chunk = statedb.execute("""SELECT FILENAME, ATTEMPTS, SRCMD5,
    CHUNKS FROM FILECPY WHERE ID = ?""", (idx,)).fetchone()
    if status == 0:
        if srcmd5 == md5sum:
            statedb.execute("""UPDATE FILECPY SET STATE = 4
                            WHERE ID = ?""", (idx,))
            MD5REMAINS -= 1
            if VERBOSE:
                if chunk < 0:
                    print "R%i: %s %s md5sum verified (%s)" \
                        % (workerrank, timestamp(), filename, md5sum)
                else:
                    print "R%i: %s %s chunk %i md5sum verified (%s)" \
                        % (workerrank, timestamp(), filename, chunk, md5sum)

        else:
            # This is bad; we got a md5 mismatch, but no IO
            # exceptions were thrown.
            attempt += 1 
            statedb.execute("""UPDATE FILECPY SET STATE = 0, SRCMD5 = NULL, ATTEMPTS = ?,
                            LASTRANK = ? WHERE ID =?""",(attempt, workerrank, idx))
            COPYREMAINS += 1
            if attempt < MAXTRIES:
                WARNINGS +=1 
                print ("R%i: %s WARNING: SILENT DATA CORRUPTION %s"
                       " md5sum  mismatch (%s:%s). Re-queuing copy %i."
                       % (workerrank, timestamp(), filename, srcmd5, md5sum, attempt))
                # TODO: Save corrupt segments of files.
                if chunk < 0:
                    corruptfile = destfile+"_CORRUPTED_%i" %attempt
                    destfile = mungePath(sourcedir, destdir, filename)
                    print ("R%i: %s Renaming corrupt file as %s for later analysis." 
                           % (workerrank, timestamp(), corruptfile))
                    os.rename (destfile, corruptfile)
            else:
                print "%s ERROR: Max number of copies reached on %s."\
                    %(timestamp(), filename)
                Abort()

    else:
        # md5 calc failed due to a detected error.
        attempt += 1
        statedb.execute("""UPDATE FILECPY SET ATTEMPTS = ?, LASTRANK = ?, STATE = 2
                        WHERE ID =?""",(attempt, workerrank, idx))
        if attempt < MAXTRIES:
            WARNINGS += 1
            print ("R%i: %s WARNING: Error calculating destination"
                   " md5sum of %s on attempt %i. Re-trying..." \
                       %(workerrank, timestamp(), filename, attempt))
        else:
            # Retries exceeded.
            print ("R%i %s ERROR: Max number of md5 attempts reached on %s."
                   %(timestamp(), filename))
            Abort()
    return()

def processCopy(statedb, payload):
    global WARNINGS
    global COPYREMAINS
    global MD5REMAINS

    md5sum = payload[0]
    idx = payload[1]
    workerrank = payload[2]
    status = payload[3]
    speed = payload[4]
    size = payload[5]
    stripestatus = payload[6]

    filename, attempt, chunk = statedb.execute("""SELECT FILENAME, ATTEMPTS, CHUNKS FROM FILECPY 
                        WHERE ID = ?""",(idx, )).fetchone()

    # Copy is complete. 
    if status == 0 or status == 4:
        statedb.execute("""UPDATE FILECPY SET STATE = 2, SRCMD5 = ?, LASTRANK = ?,
                        SIZE = ? WHERE ID = ? """,(md5sum, workerrank, size, idx))
        COPYREMAINS -= 1
        if VERBOSE:
            stripetxt = ""
            if LSTRIPE or FORCESTRIPE:
                if stripestatus == 1:
                    stripetxt = "(striped)"
                elif stripestatus == 0:
                    stripetxt = "(unstriped)"
                elif stripestatus == -1:
                    stripetxt = "(small file: ignored striping)"

            if chunk < 0:
                print "R%i: %s copied %s %s %s (%s/s)" \
                    % (workerrank, timestamp(), filename, stripetxt,
                       prettyPrint(size), prettyPrint(speed))
            else:
                print "R%i: %s copied %s chunk %i %s (%s/s)" \
                    % (workerrank, timestamp(), filename, chunk,
                       prettyPrint(size), prettyPrint(speed))

            if status == 4:
                # unable to preserve permissions
                WARNINGS += 1
                print ("R%i: %s WARNING: unable to preserve"
                       " attributes on %s") \
                       % (workerrank, timestamp(), filename)
    # copy failed.
    elif status ==1:
        if attempt < MAXTRIES:
            attempt += 1
            statedb.execute("""UPDATE FILECPY SET ATTEMPTS = ?,
                            LASTRANK = ?, STATE = 0 WHERE ID = ? """,(attempt, 
                                                                     workerrank, idx))
            WARNINGS += 1
            print ("R%i: %s WARNING: Error copying %s on attempt %i"
                   " Retrying..."
                   % (workerrank, timestamp(), filename,
                      attempt))
        else:
            print "%s ERROR: Max number of copies reached on %s" \
                %(timestamp(), filename)
            Abort()

    # Copy failed permenantly but non-fatally. Mark as done without bothering to retry.
    elif status == 2:
        # nonstandard filetype
        statedb.execute("""UPDATE FILECPY SET STATE = ?
        WHERE ID = ? """,(ENDSTATE, idx))
        COPYREMAINS -= 1
        MD5REMAINS -= 1
        WARNINGS +=1 
        print "R%i: %s WARNING: unable to copy %s (%s). Skipping..." \
            % (workerrank, timestamp(), filename, md5sum)
    elif status == 3:
        # permission denied
        statedb.execute("""UPDATE FILECPY SET STATE = ? 
        WHERE ID = ? """,(ENDSTATE, idx))
        COPYREMAINS -= 1
        MD5REMAINS -= 1
        WARNINGS += 1
        print "R%i: %s WARNING: permission denied on %s. Skipping..." \
            % (workerrank, timestamp(), filename)

    elif status == 5:
        # File does not exist. We do retry here, as we might be on
        # a node that does not have the FS mounted.
        if attempt < MAXTRIES:
            attempt += 1
            statedb.execute("""UPDATE FILECPY SET STATE = 0, ATTEMPTS = ?,
                            LASTRANK = ? WHERE ID = ?""", 
                            (attempt, workerrank, idx))
            WARNINGS += 1
            print ("R%i: %s WARNING: %s does not exist on"
                   " attempt %i. Retrying..."
                   % (workerrank, timestamp(), filename, attempt))
        else:
            # Treat non-existance as a non-fatal error.
            # The user might simply have moved the file during the copy
            statedb.execute("""UPDATE FILECPY SET STATE = ?, SRCMD5 = ? 
                            WHERE ID = ? """,(ENDSTATE, md5sum, idx))
            COPYREMAINS -= 1
            MD5REMAINS -= 1
            WARNINGS += 1 
            print ("R%i: %s WARNING %s does not exist: on "
                   "attempt %i. Maybe someone moved the file?"
                   " Skipping...") %(workerrank, timestamp(),
                                     filename, attempt)

    elif status == 6:
        chunks = int(math.ceil(size / float(CHUNKSIZE)))
        with statedb:
            for i in range(chunks):
                statedb.execute("INSERT INTO FILECPY (FILENAME, CHUNKS) VALUES (?,?)",
                           (filename, i))
            statedb.execute("DELETE FROM FILECPY WHERE ID = ?", (idx,))
            COPYREMAINS += chunks-1
            if MD5SUM:
                MD5REMAINS += chunks-1

        if VERBOSE:
            stripetxt = ""
            if LSTRIPE or FORCESTRIPE:
                if stripestatus == 1:
                    stripetxt = "(striped)"
                elif stripestatus == 0:
                    stripetxt = "(unstriped)"
                elif stripestatus == -1:
                    stripetxt = "(small file: ignored striping)"
            print ("R%i: %s Large file %s ; copying in %i chunks." 
                   %(workerrank, filename, stripetxt, chunks))
    return()

def ShutdownWorkers(starttime):
    """Tell workers we have no more work for them and collate the stats"""
    totalfiles = 0
    totalbytes = 0
    if VERBOSE:
        print "R0: Sending SHUTDOWN to workers"

    for r in range(1, workers):
        msg = ("SHUTDOWN",())
        comm.send(msg, dest=r, tag=1)
        if VERBOSE:
            print "rank %i shutdown" % r

    if VERBOSE:
        print "R0: Gathering results"
    data = comm.gather(0, root=0)

    # Gather the runtime statistics
    endtime = time.time()
    totalelapsedtime = endtime - starttime

    print ""
    print "Transfer Statisics:"
    print ""

    for r in range(1, workers):
        filescopied, md5done, bytescopied, byteschksummed, copytime, \
            md5time = data[r]
        totalfiles += filescopied
        totalbytes += bytescopied

        # If tasks did not do anything, set time=1; prevent div by
        # zero in the stats calcs below.
        if filescopied == 0:
            copytime = 1
        if md5done == 0:
            md5time = 1

        print "Rank %i copied %s in %i files (%s/s)" \
            % (r, prettyPrint(bytescopied), filescopied,
               prettyPrint(bytescopied / copytime))
        if MD5SUM:
            print "Rank %i checksummed %s in %i files (%s/s)" \
                % (r, prettyPrint(byteschksummed), md5done,
                   prettyPrint(byteschksummed / md5time))

    print ("Total data copied: %s in %i files (%s/s)" 
           %(prettyPrint(totalbytes), totalfiles,
             prettyPrint(totalbytes / totalelapsedtime)))
    print ("Total Time for copy: %s" 
           %time.strftime("%H hrs %M mins %S secs", 
                          time.gmtime(totalelapsedtime)))
    print "Warnings %i" % WARNINGS

def createDir(sourcedir, destdir, statedb, idx):
    """Create destdir, setting stripe attributes to be the
    same as sourcedir. Timestamps are save in the statedb for use later."""
    global WARNINGS

    # Don't worry is the destination directory already exists
    if VERBOSE:
        print "R%i: %s mkdir %s" % (rank, timestamp(), destdir),

    try:
        os.mkdir(destdir)
    except OSError, error:
        if error.errno != 17:
            raise

    if PRESERVE:
        try:
            stat = safestat(sourcedir)
            statedb.execute("UPDATE DIRLIST SET ATIME = ? , MTIME = ? WHERE ID =?",
                            (stat.st_atime, stat.st_mtime, idx))
            os.chmod(destdir, stat.st_mode)
            os.chown(destdir, stat.st_uid, stat.st_gid)
            # Don't worry if we can't set the permissions/uid to be the same
            # as the previous side; we might be copying someone else's data.
        except OSError, error:
            if error.errno != 1:
                raise
            else:
                print "R%i WARNING: Unable to set permissions on %s" \
                    % (rank, destdir)
                WARNINGS += 1

    try:
        if LSTRIPE or FORCESTRIPE:
            if LSTRIPE:
                layout = lustreapi.getstripe(sourcedir)
            if (LSTRIPE and layout.isstriped()) or ( FORCESTRIPE and not NODIRSTRIPE ):
                if VERBOSE:
                    print "(striped)"
                lustreapi.setstripe(destdir, stripecount=-1)
            else:
                if VERBOSE:
                    print "(non striped)"
                lustreapi.setstripe(destdir, stripecount=1)
        else:
            if VERBOSE:
                print ""
    except IOError, error:
        if error.errno != 13:
            raise
        else:
            print "R%i WARNING: Unable to set striping on %s" \
                % (rank, destdir)


def fixupDirTimeStamp(sourcedir, destdir, statedb):
    for dirname, atime, mtime in statedb.execute("""SELECT DIRNAME, ATIME, MTIME  FROM DIRLIST"""):
        destination = mungePath(sourcedir, destdir, dirname)
        os.utime(destination, (atime, mtime))

def mungePath(src, dst, f):
    """Convert the sourcepath to the desinationpath"""
    suffix = f.partition(src)[2]
    dest = dst + suffix
    return(dest)

def safestat(filename):
    """lstat sometimes get Interrupted system calls; wrap it up so we can
    retry"""
    while True:
        try:
            statdata = os.lstat(filename)
            return(statdata)
        except IOError, error:
            if error.errno != 4:
                raise

def copyFile (src, dst, chunk):
    """Copy a file from src to dst. The copy is lustre stripe aware.
    Returns (bytes copied,speed,md5sum,stripestatus,status).
    status = 0 # copy worked
    status = 1 # IO error
    status = 2 # non standard filetype
    status = 3 # permission denied
    status = 4 # unable to preserve permissions
    status = 5 # file does not exist
    status = 6 # file is to be copied in chunks
    """

    md5sum = None
    speed = 0
    status = 0
    stripestatus = 0   # 0 non-striped, 1 striped, -1, ignored.
    starttime = time.time()

    srcstat = safestat(src)
    mode = srcstat.st_mode
    size = srcstat.st_size
    blksize = srcstat.st_blksize
    
    # regular files
    if stat.S_ISREG(mode):
        if size > CHUNKSIZE:
            # We've found a large file
            if chunk == -1:
                if LSTRIPE or FORCESTRIPE:
                    stripestatus = createstripefile(src, dst, size)
                # Create a spare file to fill in later.
                outfile = open(dst, "wb")
                outfile.truncate(size)
                outfile.close()
                return(size, 0, 0, stripestatus, 6)

        else:
            if LSTRIPE or FORCESTRIPE:
                stripestatus = createstripefile(src, dst, size)


        if DRYRUN:
            md5sum = "DEADBEAFdeadbeafDEADBEAFdeadbeaf"
            bytescopied = 0
        else:
            if PRESERVE:
                md5sum, bytescopied = md5copy(src, dst, blksize, MD5SUM, chunk)
                try:
                    os.chown(dst, srcstat.st_uid, srcstat.st_gid)
                    os.chmod(dst, srcstat.st_mode)
                    os.utime(dst, (srcstat.st_atime, srcstat.st_mtime))
                except OSError, error:
                    # Can preserve the permissions
                    if error.errno == 1:
                        status = 4
                    else:
                        raise
            else:
                md5sum, bytescopied = md5copy(src, dst, blksize, MD5SUM, chunk)
            if VERBOSE:
                endtime = time.time()
                if size == 0:
                    speed = 0
                else:
                    speed = bytescopied / (endtime - starttime)
        return(bytescopied, speed, md5sum, stripestatus, status)

    # symlinks
    if stat.S_ISLNK(mode):
        if DRYRUN:
            md5sum = "DEADBEAFdeadbeafDEADBEAFdeadbeaf"
        else:
            linkto = os.readlink(src)
            try:
                os.symlink(linkto, dst)
            except OSError, error:
                if error.errno == 17:
                    os.remove(dst)
                    os.symlink(linkto, dst)
                else:
                    raise
            if PRESERVE:
                try:
                    os.lchown(dst, srcstat.st_uid, srcstat.st_gid)
                except OSError, error:
                    if error.errno == 1:
                        status = 4
                    else:
                        raise
        return(0, 0, md5sum, 0, 0)

    # special files
    filemode = stat.S_IFMT(mode)
    if filemode == 0010000:
        filetype = "FIFO"
    elif filemode == 0020000:
        filetype = "character device"
    elif filemode == 0060000:
        filetype = "block device"
    elif filemode == 0140000:
        filetype = "socket"
    else:
        filetype = "unknown"
    return(0, 0, filetype, 0, 2)

def prettyPrint(bytes):
    """convert bytes to k/M/G/T etc"""
    abrevs = (
        (1<<50,"Pbytes"),
        (1<<40,"Tbytes"),
        (1<<30,"Gbytes"),
        (1<<20,"Mbytes"),
        (1<<10,"kbytes"),
        (1,"bytes")
        )

    for factor, suffix in abrevs:
        if bytes >= factor:
            break
    string = "%.*f %s" % (2, bytes / float(factor), suffix)
    return (string)


def SIConvert(amount):
    """convert human readable size to bytes (eg 1k -> 1024). Returns -1 if
    the format is unknown."""

    table = dict(K=1, k=1, M=2, G=3, T=4, P=5)

    try:
        number = int(amount)
        return(number)
    except ValueError:
        pass

    try:
        number, suffix = amount[:-1], amount[-1]
        multi = table[suffix]
        number = int(number)
    except:
        return(-1)
    return(number * (1024 ** multi))

def checkVersion():
    """Check the MPI version for known buggy versions."""
    mpivendor, mpiversion = MPI.get_vendor()
    if mpivendor == "Open MPI":
        print "WARNING: appears to have problems with openmpi on"
        print "large job sizes; if pcp hangs, consider using mpich"
        print "instead."
    return()

def distribArgs(args):
    """If we have been restarted from a checkpoint we need to 
    pass the original command line arguments to all of the workers."""
    args = comm.bcast(args, root=0)
    return(args)

class MPIargparse(argparse.ArgumentParser):
    """Subclass argparse so we can add a call to Abort, to tidy up MPI bits and pieces."""
    def error(self,message):
        self.print_usage(sys.stderr)
        Abort()

    def print_help(self, file=None):
        argparse.ArgumentParser.print_help(self, file=None)
        Abort()

def handler(signum, frame):
    global CHECKPOINTNOW
    if rank == 0 and STARTEDCOPY:
        CHECKPOINTNOW = True

# Main program

comm = MPI.COMM_WORLD
rank = comm.Get_rank()
workers = comm.size
hostname = os.uname()[1]

STARTEDCOPY = False  # flag to see whether we can start checkpointing.
signal.signal(signal.SIGUSR1, handler)
try:
    if rank == 0:

        args = parseargs()        
        timeout = args.d # dead worker timeout
        # If we are a restored job, read in our arguments
        # from the restoredb instead.
        
        # Older openMPIs are buggy
        checkVersion()
        
        if workers < 2:
            print ("ERROR: Only %i processes running. Did you invoke me via"
                   " mpirun?") % workers
            print ("This program requires at least 2 processes to run"
                   " correctly.")
            exit(0)

        if args.R:
            statedb, args = restoreDB(args.R)
            resumed = True
        else:
            resumed = False
            statedb = createDB()
            pargs = pickle.dumps(args)
            statedb.execute("""INSERT OR REPLACE INTO ARGUMENTS (ARGS, ID)
                    VALUES(?,1)""", (pargs,))
    else:
        timeout = 0
        args = 0

    # Check the workers are alive and send them the runtime arguments.
    checkAlive(rank, workers, timeout)
    args = distribArgs(args)

    MD5SUM = args.c      # checksum copy
    DRYRUN = args.dry_run  # Dry run
    MAXTRIES = args.t      # number of retries on IO error
    PRESERVE = args.p      # preserve permissions etc
    LSTRIPE = args.l       # preserve lustre information
    MINSTRIPESIZE = args.ls  # don't stripe for files smaller than this
    FORCESTRIPE = args.lf   # Stripe all files regardless of source striping
    NODIRSTRIPE = args.ld # Stripe all directories regardless of source striping
    WARNINGS = 0 # number of warning
    VERBOSE = args.v    # Should we be verbose
    DUMPDB = args.K     # Checkpoint to this directory.
    DUMPINTERVAL = args.Km * 60 # Checkpoint period
    CHECKPOINTNOW = False
    COPYREMAINS = 0 # remaining number of items to copy.
    MD5REMAINS = 0 # remaining number of items to md5.
    sourcedir = args.SOURCE.rstrip(os.path.sep) # source
    destdir = args.DEST.rstrip(os.path.sep)  # destination
    glob = args.g    # only copy files matching glob

    # 100MB
    CHUNKSIZE = 1024 * 1024 * 50

    # Set the final state of process
    if MD5SUM:
        ENDSTATE = 4
    else:
        ENDSTATE = 2

    if rank == 0:
        # master process
        print "Starting %i processes." % workers

        if resumed:
            print ("Resuming a copy from a checkpoint. Command line parameters"
                   " will be taken from the checkpoint file.")
            print "SOURCE %s" %sourcedir
            print "DESTINATION %s" %destdir

        if DUMPDB:
            print "Will checkpoint every %i minutes to %s" %(DUMPINTERVAL, DUMPDB)
        if LSTRIPE:
            print "Will copy lustre stripe information."
        if FORCESTRIPE:
            print "Will force stripe all files."
        if (LSTRIPE or FORCESTRIPE) and NODIRSTRIPE:
            print "Will not stripe directories."
        if (LSTRIPE or FORCESTRIPE) and  MINSTRIPESIZE > 0:
            print "Will not stripe files smaller than %s" \
                % prettyPrint(MINSTRIPESIZE)
        if MD5SUM:
            print "Will md5 verify copies."

        sanitycheck(sourcedir, destdir)
        starttime = time.time()

        if not resumed:
            scantree(sourcedir, statedb)
            if glob:
                totalfiles = statedb.execute("SELECT COUNT(*) FROM FILECPY").fetchone()[0]
                results = statedb.execute("DELETE FROM FILECPY WHERE NOT FILENAME GLOB ?",
                                          (glob,))
                matchingfiles = statedb.execute("SELECT COUNT(*) FROM FILECPY").fetchone()[0]

                print "Will only copy files matching %s (%i of %i)" \
                    % (glob, matchingfiles, totalfiles)
            print "R0: Copying directories..."
            copyDirectories(sourcedir, destdir, statedb)

        STARTEDCOPY = True
        print "Copying files..."
        DispatchWork(statedb)
        if PRESERVE:
            print "R0: %s Setting directory timestamps..." %timestamp()
            fixupDirTimeStamp(sourcedir, destdir, statedb)
            print "RO: %s Done." %timestamp()
        ShutdownWorkers(starttime)
        print "Master process done."
        exit(0)

    else:
        # file copy workers
        ConsumeWork(sourcedir, destdir)
        exit(0)

# We need to call MPI ABORT in our exception handler,
# otherwise the other MPI processes spin forever.
#except Exception, err:
except  (Exception, KeyboardInterrupt), err:
    print "Exception on rank %i host %s:" %(rank, hostname)
    print traceback.format_exc()
    Abort()
