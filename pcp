#!/usr/bin/python
""" This program copies a directory tree in parallel.

Algorithm:

pcp implements a master-slave pattern. R0 is the master and R1...RX are the
slaves. R0 scan the source directory tree and put files to be copied on a
queue on the master. The master dispatches files in the queue to ranks R1..RX,
which do the copy."""
# Parallel cp program
# Copyright (c) Genome Research Ltd 2012
# Author Guy Coates <gmpc@sanger.ac.uk>
# This program is released under GNU Public License V2 (GPLv2)

#import rpdb2
#rpdb2.start_embedded_debugger(XXXX, fAllowRemote=True,timeout=1)

import argparse
import hashlib
import fnmatch
import os
import stat
import sys
import traceback
import time
import ctypes
import sqlite3
import pickle
import signal

from lustre import lustreapi
from collections import deque
from mpi4py import MPI
import pkg_resources

__version__ = pkg_resources.require("pcp")[0].version

# Ctypes boilerplate for readdir/opendir/closedir
clib = ctypes.CDLL("libc.so.6", use_errno=True)

class dirent(ctypes.Structure):
    _fields_ = [
        ("ino_t", ctypes.c_ulong),
        ("off_t", ctypes.c_ulong),
        ("d_reclen", ctypes.c_short),
        ("d_type",  ctypes.c_char ),
        ("d_name", ctypes.c_char * 4000)
]

class c_dir(ctypes.Structure):
    pass

dirent_p = ctypes.POINTER(dirent)
c_dir_p = ctypes.POINTER(c_dir)
opendir = clib.opendir
opendir.argtypes = [ctypes.c_char_p]
opendir.restype = c_dir_p
closedir = clib.closedir
closedir.argtypes = [c_dir_p]
closedir.restype = ctypes.c_int
readdir = clib.readdir
readdir.argtypes = [c_dir_p]
readdir.restype = dirent_p

class Timer:
    """Simple timer / stopwatch class."""
    def __init__(self):
        self.running = False
        self.elapsedtime = 0
        self.stoptime = 0
        self.starttime = 0

    def reset(self):
        """Reset the timer to 0."""
        self.__init__()

    def start(self):
        """Start the timer."""
        self.running = True
        self.starttime = time.time()

    def stop(self):
        """Stop the timer."""
        self.running = False
        self.stoptime = time.time()
        self.elapsedtime += self.stoptime - self.starttime

    def read(self):
        """Get the elapsed time."""
        if self.running:
            return (time.time() - self.starttime) + self.elapsedtime
        else:
            return self.elapsedtime

def createDB():
# This database holds all the information about files to be copied,
# their checksums as well as the state of the copy.
# State 
# 0 Not copied.
# 1 Dispatched for copy.
# 2 Copy complete.
# 3 Dispatched for md5
# 4 md5 complete

    filedb = sqlite3.connect(":memory:")
    filedb.text_factory = str
    filedb.execute("""CREATE TABLE FILECPY(
ID INTEGER PRIMARY KEY AUTOINCREMENT,
FILENAME TEXT,
STATE INTEGER DEFAULT 0,
SRCMD5 TEXT,
SIZE INTEGER,
ATTEMPTS INTEGER DEFAULT 0,
LASTRANK INTEGER DEFAULT 0)""")
    filedb.execute("""CREATE INDEX SIZE_IDX ON FILECPY(SIZE)""")
    filedb.execute("""CREATE INDEX STATE_IDX ON FILECPY(STATE)""")
    filedb.execute("""CREATE INDEX LAST_IDX ON FILECPY(LASTRANK)""")
    # Table to hold program arguments
    filedb.execute("""CREATE TABLE ARGUMENTS(
ID INTEGER PRIMARY KEY AUTOINCREMENT,
ARGS BLOB)""")
    return(filedb)

# Dump the database out to disk
def dumpDB(statedb, filename):
    tmpfile = filename+"__PARTIAL__"
    dbfile = open(tmpfile, "wb")
    for l in statedb.iterdump():
        dbfile.write(l + "\n")
    dbfile.close()
    os.rename(tmpfile, filename)

# Restore the database state from a previous run so we
# can resume a copy.
def restoreDB(filename):
    filedb = sqlite3.connect(":memory:")
    filedb.text_factory = str
    dumpfile = open(filename, "rb")
    filedb.executescript(dumpfile.read())
    filedb.commit()
    dumpfile.close()
    argp = filedb.execute("SELECT ARGS FROM ARGUMENTS WHERE ID == 1").fetchone()
    args = pickle.loads(argp[0])

    filedb.execute("UPDATE FILECPY SET STATE = 0 WHERE STATE = 1;")
    filedb.execute("UPDATE FILECPY SET STATE = 2 WHERE STATE = 3;")
    filedb.execute("UPDATE FILECPY SET ATTEMPTS = 0;")
    filedb.execute("UPDATE FILECPY SET LASTRANK = 0;")
    return(filedb, args)
    

def parseargs():
    parser = MPIargparse(description=
                                     "Copy a directory tree in parallel",
                                     formatter_class =
                                     argparse.RawDescriptionHelpFormatter,
                                   epilog="""

This program traverses a directory tree and copies files in the tree in
parallel. It does not copy individual files in parallel. It should be invoked
via mpirun.

If run with the -l flag, pcp will be lustre stripe aware. When it encounters
a striped file it will stripe the copy across all OSTs at the destination. Note
that it does not exactly preserve stripe information.

If a size is specified with -ls, pcp will not stripe files smaller than this,
even if the original is striped.

For maximum efficiency, ensure tasks are spread across as many different
machines as possible to prevent local network bottlenecks.

""")


    parser.add_argument("SOURCE", help="source directory", nargs="?")
    parser.add_argument("DEST", help="destination directory", nargs="?")

    parser.add_argument("-c", help="verify copy with checksum", default=False,
                        action="store_true")
    parser.add_argument("-d", help="dead worker timeout (seconds)", default=10,
                        type=int)
    parser.add_argument("-g", help="only copy files matching glob",
                        default=None)
    parser.add_argument("-n", "--dry-run",
                        help="perform a trial run with no copies made",
                        action="store_true", default=False)
    parser.add_argument("-t",
                        help="retry file copies N times in case of IO errors",
                        type=int, metavar="N", default=3)
    parser.add_argument("-p", help="preserve ownership/permissions",
                        default=False, action="store_true")
    parser.add_argument("-v", help="verbose", default=False,
                        action="store_true")
    parser.add_argument("-V", "--version", help="print version number",
                        action='version',
                        version=os.path.basename(sys.argv[0]) + \
                            " version " + __version__)
    group = parser.add_mutually_exclusive_group()
    group.add_argument("-l", help="copy lustre stripe information",
                       default=False, action="store_true")
    group.add_argument("-lf",
                       help=("Force striping of all files. Can be combined"
                             "with -ls."), default=False, action="store_true")
    parser.add_argument("-ls",
                        help=("do not stripe files smaller than B "
                              "bytes. Implies -l. Size can be suffixed"
                              "with k,M,G,T,P"), metavar="B", default=0)
    parser.add_argument("-R",
                        help=("Restart a copy from a checkpoint file DUMPFILE."),
                        type=str, metavar="DUMPFILE", default=None)

    parser.add_argument("-K",
                       help=("Enable and write checkpoints to file DUMPFILE."),
                       type=str, metavar="DUMPFILE", default=None)
    parser.add_argument("-Km",
                        help=("Checkpoint every N minutes."),
                        type=int, metavar="N", default=60)

    if len(sys.argv) == 1:
        parser.print_help()
        Abort()
        
    args = parser.parse_args()

    if not args.SOURCE and  not args.R:
        print "You must specify a source directory!"
        parser.print_help()
        Abort()

    if not args.DEST and  not args.R:
        print "You must specify a destination directory!"
        parser.print_help()
        Abort()

    if args.ls != 0:
        args.l = True
        args.ls = SIConvert(args.ls)
        if args.ls == -1:
            print "Error: incorrect size specification."
            Abort()
    return(args)

def Abort():
    if rank == 0 and STARTEDCOPY and DUMPDB:
        try:
            print "Attempting write state database to %s..." %(DUMPDB),
            dumpDB(statedb, DUMPDB)
            print "Done."
        except IOError as dberr:
            print "FAILED!" 
            print dberr

    """Clean down all the MPI Processes."""
    MPI.COMM_WORLD.Abort(1)
    exit (1)

def sanitycheck(sourcedir, destdir):
    """Perform some sanity checks, including creating the destination
    directory if it does not exist and ensuring excessive parallelism is not
    used."""

    realsource = os.path.realpath(sourcedir)
    realdest = os.path.realpath(destdir)
    if realsource == realdest:
        print 
        print ("ERROR: Source and destination directory are the same!")
        print
        Abort()
        
    # if lustre option is set, check we are on a lustre filesystem.
    if LSTRIPE or FORCESTRIPE:
        try:
            lustreapi.getstripe(sourcedir)
        except IOError, error:
            if error.errno == 25:
                print ("ERROR: %s is not a lustre directory but lustre stripe"
                       " preservation is set.") % sourcedir
                print "Exiting."
                Abort()
    #Create the top level destdir if it does not already exist
    attemptCreateDir(sourcedir, destdir)

def scantree(sourcedir, statedb):
    """Scans sourcedir recursively and returns a list of filestate objects and
    a list of directories."""
    dirlist = []

    print "R%i: Scanning list of files to copy..." % (rank)
    if not  os.path.isdir(sourcedir):
        print "R%i: Error: %s not a directory" % (rank, sourcedir)
        Abort()
    startime = time.time()
    for source, dirs, files in fastwalk(sourcedir):
        dirlist.extend([(os.path.join(source, d)) for d in dirs ])
        fullpath = [ (os.path.join(source,f),) for f in files ]
        statedb.executemany("""INSERT INTO FILECPY (FILENAME) VALUES (?)""",
                            fullpath)

    endtime = time.time()
    walltime = endtime - startime
    totalfiles = statedb.execute("SELECT COUNT(*) FROM FILECPY").fetchone()[0]
    totaldirs = len(dirlist)
    rate = (totalfiles + totaldirs) / walltime
    print ("R%i: Scan Done. Did %i files, %i dirs in %i seconds"
           " (%.0f items/sec)."
        % (rank, totalfiles, totaldirs, walltime, rate))
    return(dirlist)

def fastwalk (sourcedir):
    """Improved version of os.walk: generates a tuple of (sourcedir,[dirs],
    [files]). This version tries to use readdir to avoid expensive stat
    operations on lustre."""

    filelist = []
    dirlist = []
    global WARNINGS
    dirp = opendir(sourcedir)
    if not bool(dirp):
        print "R%i WARNING: Cannot open %s:"  % (rank, sourcedir),
        print os.strerror(ctypes.get_errno())
        WARNINGS += 1
    else:
        while True:
            p = readdir(dirp)
            if not p:
                break
            name = p.contents.d_name
            filetype = p.contents.d_type
            if not name in (".",".."):
                if filetype == "\x00":
                    # Filesystem does not support d_type, so we hae to do
                    # the stat.
                    fullname = os.path.join(sourcedir, name)
                    mode = safestat(fullname).st_mode
                    if stat.S_ISDIR(mode):
                        filetype = "\x04"
                    else:
                        filetype = "\x08"
                if filetype == "\x04":
                    dirlist.append(name)
                else:
                    filelist.append(name)
        closedir(dirp)

    yield (sourcedir, dirlist, filelist)
    for d in dirlist:
        fullname = os.path.join(sourcedir, d)
        for entries in fastwalk(fullname):
            yield entries

def fadviseSeqNoCache(fileD):
    """Advise the kernel that we are only going to access file-descriptor
    fileD once, sequentially."""
    POSIX_FADV_SEQUENTIAL = 2
    POSIX_FADV_DONTNEED = 4
    offset = ctypes.c_int64(0)
    length = ctypes.c_int64(0)
    clib.posix_fadvise(fileD, offset, length, POSIX_FADV_SEQUENTIAL)
    clib.posix_fadvise(fileD, offset, length, POSIX_FADV_DONTNEED)

def md5copy(src, dst, blksize, MD5SUM):
    """Combined copy / md5 calcuation function. Copies data from src to dst in
    blksize chunks. If MD5SUM is true, it also calculates the md5sum of the
    source file. Returns the md5sum of the source."""
    md5hash = hashlib.new("md5")
    infile = open(src, "rb")
    outfile = open(dst, "wb")
    fadviseSeqNoCache(infile.fileno())
    fadviseSeqNoCache(outfile.fileno())
    while True:
        data = infile.read(blksize)
        if not data:
            break
        outfile.write(data)
        if MD5SUM:
            md5hash.update(data)
    infile.close()
    outfile.close()
    digest = md5hash.hexdigest()
    if not MD5SUM:
        digest = None
    return(digest)

def calcmd5(filename):
    """calculate the md5sum of a file. Returns a tuple of  (md5sum,amount of
    data checksummed), or (None,0) in the case of symlinks."""
    md5hash = hashlib.new("md5")

    # Use the optimal blocksize for IO.
    filestat = safestat(filename)
    blksize = filestat.st_blksize
    size = filestat.st_size
    mode = filestat.st_mode

    if stat.S_ISLNK(mode):
        return(None, 0)

    fh = open(filename, "rb")
    fadviseSeqNoCache(fh.fileno())

    while True:
        data = fh.read(blksize)
        if not data:
            break
        md5hash.update(data)
    fh.close()
    digest = md5hash.hexdigest()
    return(digest, size)


def ConsumeWork(sourcedir, destdir):
    """Listen for work from the dispatcher and copies/md5sums files as
    appropriate. When send the SHUTDOWN message the worker will send
    performance stats back to the master."""

    filescopied = 0
    md5done = 0
    bytescopied = 0
    byteschksummed = 0
    md5timer = Timer()
    copytimer = Timer()

    # Poll for work.
    while True:
        data = comm.recv(source=0, tag=1)
        if data == "SHUTDOWN":
            break

        action, filename, idx = data
        md5sum = None
        destination = mungePath(sourcedir, destdir, filename)

        if action == "COPY":
            copytimer.start()
            try:
                bytes, speed, md5sum, stripestatus, status = \
                    copyFile(filename, destination)

            except (IOError, OSError) as error:
                speed = 0
                bytes = 0
                stripestatus = 0
                # permission denied errors are not fatal. Skip over the file
                # and carry on.
                if error.errno == 13:
                    status = 3
                # File might have moved whilst we copied it!
                elif error.errno == 2:
                    status = 5
                else:
                    status = 1

            if status == 0 or status == 4 :
                bytescopied += bytes
                filescopied += 1
            comm.send(("COPYRESULT", md5sum, idx, rank, status, speed,
                       bytes, stripestatus), dest=0, tag=1)
            copytimer.stop()

        if action == "MD5":
            md5timer.start()
            if DRYRUN:
                size = 0
                status = 0
                md5sum = "DEADBEAFdeadbeafDEADBEAFdeadbeaf"
            else:
                try:
                    md5sum, size = calcmd5(destination)
                    status = 0
                except (IOError, OSError):
                    size = 0
                    status = 1

            comm.send(("MD5RESULT", md5sum, idx, rank, status,
                       None, None, None), dest=0, tag=1)
            md5done += 1
            byteschksummed += size
            md5timer.stop()

    # Return stats
    comm.gather((filescopied, md5done, bytescopied, byteschksummed,
                 copytimer.read(), md5timer.read()), root=0)
    return(0)

def copyDirectories(sourcedir, destdir, dirlist):
    """Copy a list of directories (dirlist) from sourcedir to destdir"""
    for d in dirlist:
        destination = mungePath(sourcedir, destdir, d)
        attemptCreateDir(d, destination)


def checkAlive(rank, workers, timeout):
    """Quirky farm nodes can cause the MPI runtime to lock up during the task
    spawn. This routine checks whether nodes can exchange messages. If a node
    has not responded after timeout seconds we bail."""

    if rank > 0:
        comm.send(("ALIVE", rank), dest=0, tag=3)
    else:
        expectedworkers = set(range(1, workers))
        aliveworkers = set()
        giveuptime = time.time() + timeout
        while time.time() < giveuptime:
            if comm.Iprobe(source=MPI.ANY_SOURCE, tag=3):
                status, rank = comm.recv(source=MPI.ANY_SOURCE, tag=3)
                aliveworkers.add(rank)
                if len(aliveworkers) == len(expectedworkers):
                    print "R0: All workers have reported in."
                    return
        print ("Error: The following workers did not report in after"
               " %i seconds") % timeout
        awol = expectedworkers.difference(aliveworkers)
        for i in awol:
            print "R%i" % i
        Abort()

def DispatchWork(statedb):
    """The dispatcher sends  copy/md5 tasks out to idle workers. If copy/md5
    tasks fail the dispatcher will re-queue them for retries."""

    global WARNINGS
    global CHECKPOINTNOW
    # Queue containing worker who are ready for work.
    idleworkers = deque()
    idleworkers.extend(range(1, workers))
    # Start the checkpoint timer
    if DUMPDB:
        cptimer = Timer()
        cptimer.start()

    # loop until we have no more work to send.
    while True:
        # See if we need to checkpoint
        if DUMPDB:
            if cptimer.read() > DUMPINTERVAL * 60:
                print "RO: Writing checkpoint to %s..." %DUMPDB,
                dumpDB(statedb, DUMPDB)
                print "Done"
                cptimer.reset()
                cptimer.start()

        if CHECKPOINTNOW:
            if not DUMPDB:
                dumpfile = "pcp_checkpoint.db"
            else:
                dumpfile = DUMPDB
            print "R0: SIGUSR1: Writing checkpoint to %s..." %dumpfile,
            dumpDB(statedb, dumpfile)
            print "Done"
            CHECKPOINTNOW = False

        remains = statedb.execute \
            ("""SELECT COUNT(*) FROM FILECPY WHERE STATE <> ?""",(ENDSTATE, )).fetchone()[0]
        if remains == 0:
            break

        # Listen for workers reporting in and deal with the results
        if comm.Iprobe(source=MPI.ANY_SOURCE, tag=1):
            action, md5sum, idx, workerrank, status, speed, size, \
                stripestatus = comm.recv(source=MPI.ANY_SOURCE, tag=1)
            idleworkers.appendleft(workerrank)

            if action == "COPYRESULT":
                processCopy(statedb, md5sum, idx, workerrank, status, size, speed,
                            stripestatus)

            if action == "MD5RESULT":
                processMD5(statedb, md5sum, idx, workerrank, status)

        # try for dispatch
        if len(idleworkers) > 0:
            worker = idleworkers.pop()
            
            # 2 workers is a special case; we can't do MD5sum or retries on
            # a different nodes, as we only have 1 worker node.
            if workers == 2:
                lastrank = -1
            else:
                lastrank = worker

            task = statedb.execute("""SELECT * FROM FILECPY WHERE STATE == 0 AND
                                  LASTRANK <> ? LIMIT 1""",(lastrank, )).fetchone()
            if task:
                statedb.execute("""UPDATE FILECPY SET STATE = 1 WHERE ID = ?""",(task[0],))
                comm.send(("COPY", task[1], task[0]),
                          dest=worker, tag=1)
                continue

            if MD5SUM:
                task = statedb.execute("""SELECT * FROM FILECPY WHERE STATE == 2 AND
                       LASTRANK <> ? ORDER BY SIZE DESC LIMIT 1""",(lastrank, )).fetchone()
                if task:
                    statedb.execute("""UPDATE FILECPY SET STATE = 3 WHERE ID = ?""",(task[0],))
                    comm.send(("MD5", task[1], task[0]),
                              dest=worker, tag=1)
                    continue
            # There is work, but not for this worker. Send to the back of the queue
            idleworkers.appendleft(worker)

    if VERBOSE:
        print "R0: No more work to do."

def processMD5(statedb, md5sum, idx, workerrank, status):
    global WARNINGS
    filename, attempt, srcmd5 = statedb.execute("""SELECT FILENAME, ATTEMPTS, SRCMD5
    FROM FILECPY WHERE ID = ?""",(idx,)).fetchone()
    if status == 0:
        if srcmd5 == md5sum:
            statedb.execute("""UPDATE FILECPY SET STATE = 4
                            WHERE ID = ?""", (idx,))
            if VERBOSE:
                print "R%i: %s md5sum verified (%s)" \
                    % (workerrank, filename, md5sum)
        else:
            # This is bad; we got a md5 mismatch, but no IO
            # exceptions were thrown.
            attempt += 1 
            statedb.execute("""UPDATE FILECPY SET STATE = 0, SRCMD5 = NULL, ATTEMPTS = ?,
                            LASTRANK = ? WHERE ID =?""",(attempt, workerrank, idx))
            if attempt < MAXTRIES:
                WARNINGS +=1 
                print ("R%i: WARNING: SILENT DATA CORRUPTION %s"
                       " md5sum  mismatch (%s:%s). Re-queuing copy %i."
                       % (workerrank, filename, srcmd5, md5sum, attempt))
            else:
                print "ERROR: Max number of copies reached on %s."\
                    % filename
                Abort()

    else:
        # md5 calc failed due to a detected error.
        attempt += 1
        statedb.execute("""UPDATE FILECPY SET ATTEMPTS = ?, LASTRANK = ?, STATE = 2
                        WHERE ID =?""",(attempt, workerrank, idx))

        if attempt < MAXTRIES:
            WARNINGS += 1
            print ("R%i: WARNING: Error calculating destination"
                   " md5sum of %s. Re-attempting md5"
                   % (workerrank, filename, attempt))
        else:
            print "ERROR: Max number of md5s reached on %s." % filename
            Abort()


def processCopy(statedb, md5sum, idx, workerrank, status, size, speed, stripestatus):
    global WARNINGS
    filename, attempt = statedb.execute("""SELECT FILENAME, ATTEMPTS FROM FILECPY 
                        WHERE ID = ?""",(idx, )).fetchone()

    # Copy is complete. 
    if status == 0 or status == 4:
        statedb.execute("""UPDATE FILECPY SET STATE = 2, SRCMD5 = ?, LASTRANK = ?,
                        SIZE = ? WHERE ID = ? """,(md5sum, workerrank, size, idx))

        if VERBOSE:
            stripetxt = ""
            if LSTRIPE or FORCESTRIPE:
                if stripestatus == 1:
                    stripetxt = "(striped)"
                elif stripestatus == 0:
                    stripetxt = "(unstriped)"
                elif stripestatus == -1:
                    stripetxt = "(small file: ignored striping)"

            print "R%i: copied %s %s %s (%s/s)" \
                  % (workerrank, filename, stripetxt,
                     prettyPrint(size), prettyPrint(speed))
            if status == 4:
                # unabel to preserve permissions
                WARNINGS += 1
                print ("R%i: WARNING: unable to preserve"
                       " attributes on %s") \
                       % (workerrank, filename)                       
    # copy failed.
    elif status ==1:
        if attempt < MAXTRIES:
            attempt += 1
            statedb.execute("""UPDATE FILECPY SET ATTEMPTS = ?,
                            LASTRANK = ? STATE = 0 WHERE ID = ? """,(attempt, 
                                                                     workerrank, idx))
            WARNINGS += 1
            print ("R%i: WARNING: Error copying %s on attempt %i"
                   " Retrying..."
                   % (workerrank, filename,
                      copylist[idx].attempt))
        else:
            print ("ERROR: Max number of copies reached on %s" \
                   % filename)
            Abort()

    # Copy failed permenantly but non-fatally. Mark as done without bothering to retry.
    elif status == 2:
        # nonstandard filetype
        statedb.execute("""UPDATE FILECPY SET STATE = ?
        WHERE ID = ? """,(ENDSTATE, idx))
        WARNINGS +=1 
        print "R%i: WARNING: unable to copy %s (%s). Skipping..." \
            % (workerrank, filename, md5sum)
    elif status == 3:
        # permission denied
        statedb.execute("""UPDATE FILECPY SET STATE = ? 
        WHERE ID = ? """,(ENDSTATE, idx))
        WARNINGS += 1
        print "R%i: WARNING: permission denied on %s. Skipping..." \
            % (workerrank, filename)

    elif status == 5:
        # File does not exist. We do retry here, as we might be on
        # a node that does not have the FS mounted.
        if attempt < MAXTRIES:
            attempt += 1
            statedb.execute("""UPDATE FILECPY SET ATTEMPTS = ?,
                            LASTRANK = ? WHERE ID = ?""", 
                            (attempt, workerrank, idx))
            WARNINGS += 1
            print ("R%i: WARNING: %s does not exist on"
                   " attempt %i. Retrying..."
                   % (workerrank, filename, attempt))
        else:
            # Treat non-existance as a non-fatal error.
            # The user might simply have moved the file during the copy
            statedb.execute("""UPDATE FILECPY SET STATE = ?, SRCMD5 = ? 
                            WHERE ID = ? """,(ENDSTATE, md5sum, idx))
            WARNINGS += 1 
            print ("R%i: WARNING %s does not exist: on"
                   "attempt %i. Maybe someone moved the file?"
                   " Skipping...")


def ShutdownWorkers(starttime):
    """Tell workers we have no more work for them and collate the stats"""
    totalfiles = 0
    totalbytes = 0
    if VERBOSE:
        print "R0: Sending SHUTDOWN to workers"

    for r in range(1, workers):
        comm.send("SHUTDOWN", dest=r, tag=1)
        if VERBOSE:
            print "rank %i shutdown" % r

    if VERBOSE:
        print "R0: Gathering results"
    data = comm.gather(0, root=0)

    # Gather the runtime statistics
    endtime = time.time()
    totalelapsedtime = endtime - starttime

    print ""
    print "Transfer Statisics:"
    print ""

    for r in range(1, workers):
        filescopied, md5done, bytescopied, byteschksummed, copytime, \
            md5time = data[r]
        totalfiles += filescopied
        totalbytes += bytescopied

        # If tasks did not do anything, set time=1; prevent div by
        # zero in the stats calcs below.
        if filescopied == 0:
            copytime = 1
        if md5done == 0:
            md5time = 1

        print "Rank %i copied %s in %i files (%s/s)" \
            % (r, prettyPrint(bytescopied), filescopied,
               prettyPrint(bytescopied / copytime))
        if MD5SUM:
            print "Rank %i checksummed %s in %i files (%s/s)" \
                % (r, prettyPrint(byteschksummed), md5done,
                   prettyPrint(byteschksummed / md5time))

    print "Total data copied: %s in %i files (%s/s)" \
        % (prettyPrint(totalbytes), totalfiles,
           prettyPrint(totalbytes / totalelapsedtime))
    print "Warnings %i" % WARNINGS

def createDir(sourcedir, destdir):
    """Create destdir, setting permissions and stripe attributes to be the
    same as sourcedir"""
    global WARNINGS

    # Don't worry is the destination directory already exists
    try:
        os.mkdir(destdir)
    except OSError, error:
        if error.errno != 17:
            raise

    if PRESERVE:
        try:
            stat = safestat(sourcedir)
            os.chmod(destdir, stat.st_mode)
            os.chown(destdir, stat.st_uid, stat.st_gid)
            os.utime(destdir, (stat.st_atime, stat.st_mtime))
            # Don't worry if we can't set the permissions/uid to be the same
            # as the previous side; we might be copying someone else's data.
        except OSError, error:
            if error.errno != 1:
                raise
            else:
                print "R%i WARNING: Unable to set permissions on %s" \
                    % (rank, destdir)
                WARNINGS += 1

    try:
        if LSTRIPE or FORCESTRIPE:
            if LSTRIPE:
                layout = lustreapi.getstripe(sourcedir)

            if (LSTRIPE and layout.isstriped()) or FORCESTRIPE:
                if VERBOSE:
                    print "(striped)",
                lustreapi.setstripe(destdir, stripecount=-1)
            else:
                lustreapi.setstripe(destdir, stripecount=1)
    except IOError, error:
        if error.errno != 13:
            raise
        else:
            print "R%i WARNING: Unable to set striping on %s" \
                % (rank, destdir)

def attemptCreateDir(sourcedir, destdir):
    """Attempt to copy a directory. Retry the copy MAXTRIES in case of
    IO error."""
    global WARNINGS
    if DRYRUN:
        if VERBOSE:
            print "R%i mkdir %s" % (rank, destdir)
    else:
        i = 0
        while i < MAXTRIES:
            if VERBOSE:
                print "R%i mkdir %s" % (rank, destdir)
            try:
                createDir(sourcedir, destdir)
                break
            except IOError, error:
                i += 1
                print "WARNING: mkdir error on %s attempt %i" % (destdir, i)
                WARNINGS += 1
                if i == MAXTRIES:
                    print "ERROR: Max number of retries on %s exceeded" \
                        % sourcedir
                    raise
    return

def mungePath(src, dst, f):
    """Convert the sourcepath to the desinationpath"""
    suffix = f.partition(src)[2]
    dest = dst + suffix
    return(dest)

def safestat(filename):
    """lstat sometimes get Interrupted system calls; wrap it up so we can
    retry"""
    while True:
        try:
            statdata = os.lstat(filename)
            return(statdata)
        except IOError, error:
            if error.errno != 4:
                raise

def copyFile (src, dst):
    """Copy a file from src to dst. The copy is lustre stripe aware.
    Returns (bytes copied,speed,md5sum,stripestatus,status).
    status = 0 # copy worked
    status = 1 # IO error
    status = 2 # non standard filetype
    status = 3 # permission denied
    status = 4 # unable to preserve permissions
    status = 5 # file does not exist
    """

    md5sum = None
    speed = 0
    status = 0
    stripestatus = 0   # 0 non-striped, 1 striped, -1, ignored.
    starttime = time.time()

    srcstat = safestat(src)
    mode = srcstat.st_mode
    size = srcstat.st_size
    blksize = srcstat.st_blksize

    # regular files
    if stat.S_ISREG(mode):
        if LSTRIPE or FORCESTRIPE:
            if LSTRIPE:
                layout = lustreapi.getstripe(src)
            if (LSTRIPE and layout.isstriped()) or FORCESTRIPE:
                if size < MINSTRIPESIZE:
                    stripestatus = -1
                    count = 1
                else:
                    stripestatus = 1
                    count = -1
            else:
                count = 1
            if not DRYRUN:
                try:
                    lustreapi.setstripe(dst, stripecount=count)
                except IOError, error:
                    if error.errno == 17:
                        # file exists; blow it away and try again...
                        os.remove(dst)
                        lustreapi.setstripe(dst, stripecount=count)
                    else:
                        raise
        if DRYRUN:
            md5sum = "DEADBEAFdeadbeafDEADBEAFdeadbeaf"
        else:
            if PRESERVE:
                md5sum = md5copy(src, dst, blksize, MD5SUM)
                try:
                    os.chown(dst, srcstat.st_uid, srcstat.st_gid)
                    os.chmod(dst, srcstat.st_mode)
                    os.utime(dst, (srcstat.st_atime, srcstat.st_mtime))
                except OSError, error:
                    # Can preserve the permissions
                    if error.errno == 1:
                        status = 4
                    else:
                        raise
            else:
                md5sum = md5copy(src, dst, blksize, MD5SUM)
            if VERBOSE:
                endtime = time.time()
                if size == 0:
                    speed = 0
                else:
                    speed = size / (endtime - starttime)
        return(size, speed, md5sum, stripestatus, status)

    # symlinks
    if stat.S_ISLNK(mode):
        if DRYRUN:
            md5sum = "DEADBEAFdeadbeafDEADBEAFdeadbeaf"
        else:
            linkto = os.readlink(src)
            try:
                os.symlink(linkto, dst)
            except OSError, error:
                if error.errno == 17:
                    os.remove(dst)
                    os.symlink(linkto, dst)
                else:
                    raise
            if PRESERVE:
                try:
                    os.lchown(dst, srcstat.st_uid, srcstat.st_gid)
                except OSError, error:
                    if error.errno == 1:
                        status = 4
                    else:
                        raise
        return(0, 0, md5sum, 0, 0)

    # special files
    filemode = stat.S_IFMT(mode)
    if filemode == 0010000:
        filetype = "FIFO"
    elif filemode == 0020000:
        filetype = "character device"
    elif filemode == 0060000:
        filetype = "block device"
    elif filemode == 0140000:
        filetype = "socket"
    else:
        filetype = "unknown"
    return(0, 0, filetype, 0, 2)

def prettyPrint(bytes):
    """convert bytes to k/M/G/T etc"""
    abrevs = (
        (1<<50,"Pbytes"),
        (1<<40,"Tbytes"),
        (1<<30,"Gbytes"),
        (1<<20,"Mbytes"),
        (1<<10,"kbytes"),
        (1,"bytes")
        )

    for factor, suffix in abrevs:
        if bytes >= factor:
            break
    string = "%.*f %s" % (2, bytes / float(factor), suffix)
    return (string)


def SIConvert(amount):
    """convert human readable size to bytes (eg 1k -> 1024). Returns -1 if
    the format is unknown."""

    table = dict(K=1, k=1, M=2, G=3, T=4, P=5)

    try:
        number = int(amount)
        return(number)
    except ValueError:
        pass

    try:
        number, suffix = amount[:-1], amount[-1]
        multi = table[suffix]
        number = int(number)
    except:
        return(-1)
    return(number * (1024 ** multi))

def checkVersion():
    """Check the MPI version for known buggy versions."""
    mpivendor, mpiversion = MPI.get_vendor()
    if mpivendor == "Open MPI":
        print "WARNING: appears to have problems with openmpi on"
        print "large job sizes; if pcp hangs, consider using mpich"
        print "instead."
    return()

def distribArgs(args):
    """If we have been restarted from a checkpoint we need to 
    pass the original command line arguments to all of the workers."""
    args = comm.bcast(args, root=0)
    return(args)

class MPIargparse(argparse.ArgumentParser):
    """Subclass argparse so we can add a call to Abort, to tidy up MPI bits and pieces."""
    def error(self,message):
        self.print_usage(sys.stderr)
        Abort()

    def print_help(self, file=None):
        argparse.ArgumentParser.print_help(self, file=None)
        Abort()

def handler(signum, frame):
    global CHECKPOINTNOW
    if rank == 0 and STARTEDCOPY:
        CHECKPOINTNOW = True

# Main program

comm = MPI.COMM_WORLD
rank = comm.Get_rank()
workers = comm.size

STARTEDCOPY = False  # flag to see whether we can start checkpointing.
    # Older openMPIs are buggy
checkVersion()
signal.signal(signal.SIGUSR1, handler)
try:
    if rank == 0:

        args = parseargs()        
        timeout = args.d # dead worker timeout
        # If we are a restored job, read in our arguments
        # from the restoredb instead.
        
        if workers < 2:
            print ("ERROR: Only %i processes running. Did you invoke me via"
                   " mpirun?") % workers
            print ("This program requires at least 2 processes to run"
                   " correctly.")
            exit(0)

        if args.R:
            statedb, args = restoreDB(args.R)
            resumed = True
        else:
            resumed = False
            statedb = createDB()
            pargs = pickle.dumps(args)
            statedb.execute("""INSERT OR REPLACE INTO ARGUMENTS (ARGS, ID)
                    VALUES(?,1)""", (pargs,))
    else:
        timeout = 0
        args = 0

    # Check the workers are alive and send them the runtime arguments.
    checkAlive(rank, workers, timeout)
    args = distribArgs(args)

    MD5SUM = args.c      # checksum copy
    DRYRUN = args.dry_run  # Dry run
    MAXTRIES = args.t      # number of retries on IO error
    PRESERVE = args.p      # preserve permissions etc
    LSTRIPE = args.l       # preserve lustre information
    MINSTRIPESIZE = args.ls  # don't stripe for files smaller than this
    FORCESTRIPE = args.lf   # Stripe all files regardless of source striping
    WARNINGS = 0 # number of warning
    VERBOSE = args.v    # Should we be verbose
    DUMPDB = args.K     # Checkpoint to this directory.
    DUMPINTERVAL = args.Km # Checkpoint period
    CHECKPOINTNOW = False
    sourcedir = args.SOURCE.rstrip(os.path.sep) # source
    destdir = args.DEST.rstrip(os.path.sep)  # destination
    glob = args.g    # only copy files matching glob


    # Set the final state of process
    if MD5SUM:
        ENDSTATE = 4
    else:
        ENDSTATE = 2

    if rank == 0:
        # master process
        print "Starting %i processes." % workers

        if resumed:
            print ("Resuming a copy from a checkpoint. Command line parameters"
                   " will be taken from the checkpoint file.")
            print "SOURCE %s" %sourcedir
            print "DESTINATION %s" %destdir

        if DUMPDB:
            print "Will checkpoint every %i minutes to %s" %(DUMPINTERVAL, DUMPDB)
        if LSTRIPE:
            print "Will copy lustre stripe information."
        if FORCESTRIPE:
            print "Will force stripe all files."
        if (LSTRIPE or FORCESTRIPE) and  MINSTRIPESIZE > 0:
            print "Will not stripe files smaller than %s" \
                % prettyPrint(MINSTRIPESIZE)
        if MD5SUM:
            print "Will md5 verify copies."

        sanitycheck(sourcedir, destdir)
        starttime = time.time()

        if not resumed:
            dirlist = scantree(sourcedir, statedb)
            if glob:
                totalfiles = statedb.execute("SELECT COUNT(*) FROM FILECPY").fetchone()[0]
                results = statedb.execute("DELETE FROM FILECPY WHERE NOT FILENAME GLOB ?",
                                          (glob,))
                matchingfiles = statedb.execute("SELECT COUNT(*) FROM FILECPY").fetchone()[0]

                print "Will only copy files matching %s (%i of %i)" \
                    % (glob, matchingfiles, totalfiles)
            print "Copying directories..."
            copyDirectories(sourcedir, destdir, dirlist)

        STARTEDCOPY = True
        print "Copying files..."
        DispatchWork(statedb)
        ShutdownWorkers(starttime)
        print "Master process done."
        exit(0)

    else:
        # file copy workers
        ConsumeWork(sourcedir, destdir)
        exit(0)

# We need to call MPI ABORT in our exception handler,
# otherwise the other MPI processes spin forever.
#except Exception, err:
except  (Exception, KeyboardInterrupt), err:
    print err
    print traceback.print_tb(sys.exc_info()[2])
    Abort()
